{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfe5caa-823c-46d5-8cfb-0e323938e222",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07824ed9-5f75-4898-8e33-4252d34d7e5d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b> Do not change this script\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7caf0d9-7686-49b1-b2c8-e40575c303ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt') --> uncomment if you haven't downloaded it yet\n",
    "# nltk.download('wordnet') --> uncomment if you haven't downloaded it yet\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a281b21f-732d-48e3-8e5e-e2414af34644",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/jupyter/agra/source code/sentiment analytics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9d0340-cdf8-4707-b11a-13636ee9bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + \"data/resto-cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba13ba5d-99b3-4087-9d46-c149b89fae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['language'] == 'in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9553b2c-39e4-4e89-9b38-95437ee92bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"text\"]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0180ec-020b-4028-9fb4-a2780ef351f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b160aa-f370-4980-9793-55ccf57c0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(text):\n",
    "    text = re.sub('[0-9]+', '', str(text)) #removing numberic value\n",
    "    text = re.sub(r'#', '', text) #removing '#' symbol\n",
    "    text = re.sub(r'[\\n]+', '', text) # remove new line\n",
    "    text = re.sub(r\"^\\s+|\\s+$\", \"\", text) #remove leading and trailing spaces in a word using OR sign to delete both\n",
    "    text = re.sub(r\" +\", \" \", text) #remove multiple space betwen words\n",
    "    text = re.sub('https? :\\/\\/\\S+', '', text) #removing hyperlink / URL\n",
    "    text = re.sub(r\"\\b[a-zA\u0002Z]\\b\", \"\", text) #removing single char\n",
    "    text = re.sub('\\s+',' ',text) #removing multiple whitespace\n",
    "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\") #remove tab, new line, and back slice\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) #remove puntuation& emoji (remove all besides \\w > word dan \\s > space)\n",
    "    text = re.sub(r'(.)1+', r'1', text) # remove repeating character\n",
    "    text = re.sub(\"[^a-zA-Z]\",' ',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "def tokenize(text) :\n",
    "    text = nltk.word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "with open(path + \"dict/stopwords1.txt\") as f:\n",
    "    additional_stopwords1 = [line.strip() for line in f]\n",
    "\n",
    "with open(path + \"dict/stopwords2.txt\") as f:\n",
    "    additional_stopwords2 = [line.strip() for line in f]\n",
    "\n",
    "with open(path + \"dict/number-stopword.txt\") as f:\n",
    "    number_stopword = [line.strip() for line in f]\n",
    "    \n",
    "with open(path + \"dict/calendar-words.txt\") as f:\n",
    "    calendar_stopword = [line.strip() for line in f]\n",
    "    \n",
    "with open(path + \"dict/indonesian-region.txt\") as f:\n",
    "    region_stopword = [line.strip() for line in f]\n",
    "\n",
    "with open(path + \"dict/swear-words.txt\") as f:\n",
    "    swear_stopword = [line.strip() for line in f]\n",
    "    \n",
    "with open(path + \"dict/resto-words.txt\") as f:\n",
    "    resto_stopword = [line.strip() for line in f]\n",
    "    \n",
    "def stopword(text): # Remove stopwors in a text\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered \n",
    "    return text\n",
    "\n",
    "def Slangword(ulasan):\n",
    "    kamusSlang = eval(open(path+\"dict/combined_slang_words.txt\").read())\n",
    "    pattern = re.compile(r'\\b( ' + '|'.join (kamusSlang.keys())+r')\\b')\n",
    "    content = []\n",
    "    for kata in ulasan:\n",
    "        filterSlang = pattern.sub(lambda x: kamusSlang[x.group()],kata)\n",
    "        content.append(filterSlang.lower())\n",
    "    ulasan = content\n",
    "    return ulasan\n",
    "\n",
    "def stopwords(words):\n",
    "    return [word for word in words if word not in data]\n",
    "\n",
    "def stemmed_wrapper(term):\n",
    "    return stemmer.stem(term)\n",
    "\n",
    "def stemmingText(document):\n",
    "    return [term_dict[term] for term in document]\n",
    "\n",
    "def check_exaggeration(text):\n",
    "    \"\"\"Mengidentifikasi apakah terdapat pengulangan huruf yang berlebihan dalam teks\"\"\"\n",
    "    count = 0\n",
    "    for i, char in enumerate(text):\n",
    "        if i < len(text) - 1 and char == text[i + 1]:\n",
    "            count += 1\n",
    "    if count > len(text) * 0.3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def repair_exaggeration(text):\n",
    "    \"\"\"Menghilangkan pengulangan huruf yang berlebihan dalam teks\"\"\"\n",
    "    new_text = \"\"\n",
    "    for i, char in enumerate(text):\n",
    "        if i < len(text) - 1 and char == text[i + 1]:\n",
    "            continue\n",
    "        new_text += char\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacdb49-d876-431b-bdc0-e8d150bfe5d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c1666-7d94-407f-a603-63d977ee6e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d754ab7-6873-4c7c-94d5-3410b2075b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b3f25a1c5a4cdca8339d9a593ed1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 630 ms, sys: 11.3 ms, total: 641 ms\n",
      "Wall time: 636 ms\n"
     ]
    }
   ],
   "source": [
    "%time df['filtering'] = df['text'].swifter.apply(filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da34bc08-e64f-415a-95ab-ba9083b19e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filtering :  @tanyarlfes Part time di kopi kenangan aja ada kalo gasalah khusus mahasiswa\n",
      "after filtering :  tanyarlfes Part time di kopi kenangan aja ada kalo gasalah khusus mahasiswa\n"
     ]
    }
   ],
   "source": [
    "print('before filtering : ', df['text'].iloc[1])\n",
    "print('after filtering : ', df['filtering'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fd6dd-0ce1-42a0-a511-960fd322c332",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a84bca-4d28-4c03-9af2-9283594e1d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10a5ba8276d40a6b00938bffadd60bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.7 ms, sys: 12.6 ms, total: 70.3 ms\n",
      "Wall time: 71.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time df['casefolding'] = df['filtering'].swifter.apply(casefoldingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd3e2e1-1b93-401e-84c2-c1f74c74d961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before casefolding :  tanyarlfes Part time di kopi kenangan aja ada kalo gasalah khusus mahasiswa\n",
      "after casefolding :  tanyarlfes part time di kopi kenangan aja ada kalo gasalah khusus mahasiswa\n"
     ]
    }
   ],
   "source": [
    "print('before casefolding : ', df['filtering'].iloc[1])\n",
    "print('after casefolding : ', df['casefolding'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c677598-6d07-4fcb-a367-8af6260dcfd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Repair Exaggeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b82b1101-d423-4ee6-aaf4-c32e41d85756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86682a44fa0b4947b0477452a70cce45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 253 ms, sys: 174 µs, total: 254 ms\n",
      "Wall time: 254 ms\n"
     ]
    }
   ],
   "source": [
    "%time df['check_exaggeration'] = df['casefolding'].swifter.apply(check_exaggeration)\n",
    "check_exaggeration_df = df[df['check_exaggeration'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "089082c5-76c1-4032-beff-97b0c23b75ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total exaggeration word :  1\n"
     ]
    }
   ],
   "source": [
    "print(\"total exaggeration word : \", len(check_exaggeration_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120e53ab-7d6f-4a85-84d0-a2610dc37df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c469c72bed0d4b299c81d479d7aae6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 319 ms, sys: 4.65 ms, total: 323 ms\n",
      "Wall time: 318 ms\n"
     ]
    }
   ],
   "source": [
    "%time df['repair_exaggeration'] = df['casefolding'].swifter.apply(repair_exaggeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b21f3ed9-bc26-4fb1-a889-8a0b8ce37ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before repair_exaggeration :\n",
      " kamuuuuuuuuuu akuuuu akan menjadiii kopi kenangan \n",
      "\n",
      "after repair_exaggeration :\n",
      " kamu aku akan menjadi kopi kenangan\n"
     ]
    }
   ],
   "source": [
    "print('before repair_exaggeration :\\n', df['casefolding'].iloc[3318],'\\n')\n",
    "print('after repair_exaggeration :\\n', df['repair_exaggeration'].iloc[3318])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6759266-5d97-4231-9e42-327de0fa765e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'additional_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7643/1674826634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# custom your stopword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmore_stopword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmore_stopword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'additional_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop_factory = StopWordRemoverFactory()\n",
    "\n",
    "# custom your stopword\n",
    "more_stopword = additional_stopwords\n",
    "\n",
    "data = stop_factory.get_stop_words()+more_stopword\n",
    "stopword = stop_factory.create_stop_word_remover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "950aca14-f2e8-41e8-b0e9-1cd5ea3086ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/swifter/swifter.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# try to vectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msuppress_stdout_stderr_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mtmp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m                 \u001b[0msample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 self._validate_apply(\n",
      "\u001b[0;32m/tmp/ipykernel_7643/3388180460.py\u001b[0m in \u001b[0;36mstopwords\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstemmed_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7643/3388180460.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstemmed_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "%time df['stopwords'] = df['repair_exaggeration'].swifter.apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e943f4-83ce-4fd5-a4d4-87abd29d35ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before stopwords :\n",
      " krsynt convomf es kopi kenangan mantan rizky bilar \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'stopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stopwords'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7643/1607288540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before stopwords :\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repair_exaggeration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2494\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after stopwords :\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2494\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stopwords'"
     ]
    }
   ],
   "source": [
    "print('before stopwords :\\n', df['repair_exaggeration'].iloc[2494],'\\n')\n",
    "print('after stopwords :\\n', df['stopwords'].iloc[2494])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2d511-d150-4087-bcd1-4c38d1c03f7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f2a9d4-e6df-4689-947c-4dadf6cf2a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ed2240bcba42bb92133cdbf3eedd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 28.2 ms, total: 2.08 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%time df['tokenize'] = df['repair_exaggeration'].swifter.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0455bec6-4131-4f80-a7d3-40d8765f2c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before tokenize :\n",
      " tanyarlfes part time di kopi kenangan aja ada kalo gasalah khusus mahasiswa \n",
      "\n",
      "after tokenize :\n",
      " ['tanyarlfes', 'part', 'time', 'di', 'kopi', 'kenangan', 'aja', 'ada', 'kalo', 'gasalah', 'khusus', 'mahasiswa']\n"
     ]
    }
   ],
   "source": [
    "print('before tokenize :\\n', df['repair_exaggeration'].iloc[1],'\\n')\n",
    "print('after tokenize :\\n', df['tokenize'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a012bd-4d67-4e62-8166-76ff1df4712b",
   "metadata": {},
   "source": [
    "### Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ead188f-123f-4b41-99e6-04ef8a78e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_factory = StopWordRemoverFactory()\n",
    "\n",
    "# custom your stopword\n",
    "more_stopword = ['jir','njir','bjir','juga', 'yang','yg', 'nya', 'aja', 'loh' ,'sih', 'deh', 'an', 'ro', \n",
    "                 'aj', 'kopi','kenangan','tanyarlfes','convomfs','FOODFESS2','FOODFESS', 'hehe', 'lho',\n",
    "                'fodfes', 'worksfes', 'discountfes', 'bankneocommerce']\n",
    "\n",
    "data = stop_factory.get_stop_words()+more_stopword+additional_stopwords1+additional_stopwords2+number_stopword+calendar_stopword+region_stopword+swear_stopword+resto_stopword\n",
    "stopword = stop_factory.create_stop_word_remover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c0f105a-e027-4a82-9d7d-c22d9a2a0bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b746c363a4047daa46a43f475f78b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 s, sys: 8.2 ms, total: 3.36 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%time df['stopword'] = df['tokenize'].swifter.apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1826784-2c05-425c-a56b-987534b930b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before stopword :\n",
      " ['tanyarlfes', 'part', 'time', 'di', 'kopi', 'kenangan', 'aja', 'ada', 'kalo', 'gasalah', 'khusus', 'mahasiswa'] \n",
      "\n",
      "after stopword :\n",
      " ['part', 'time', 'kalo', 'gasalah', 'khusus', 'mahasiswa']\n"
     ]
    }
   ],
   "source": [
    "print('before stopword :\\n', df['tokenize'].iloc[1],'\\n')\n",
    "print('after stopword :\\n', df['stopword'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb6c8a-9679-4f8a-aa2a-46f8f6aaad21",
   "metadata": {},
   "source": [
    "### Formalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90ad8c1-aeab-43dd-b270-4747d7bce8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3743d002397f4ef5a2f85404158408df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 1.08 s, total: 35.6 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%time df['formalisasi'] = df['stopword'].swifter.apply(Slangword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aced0b66-6faa-4cae-8b41-61fd86faac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before formalisasi :\n",
      " ['part', 'time', 'kalo', 'gasalah', 'khusus', 'mahasiswa'] \n",
      "\n",
      "after formalisasi :\n",
      " ['part', 'time', 'kalau', 'tidak salah', 'khusus', 'mahasiswa']\n"
     ]
    }
   ],
   "source": [
    "print('before formalisasi :\\n', df['stopword'].iloc[1],'\\n')\n",
    "print('after formalisasi :\\n', df['formalisasi'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542303c0-0582-449b-bda2-a7a448a3c241",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda2da4d-f07b-4534-aac0-d64ce00c9e89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0eb631a5b74d65a2e2ff0b28f5fe46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21271 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "term_dict = {}\n",
    "\n",
    "for document in df['formalisasi']:\n",
    "    for term in document:\n",
    "        if term not in term_dict:\n",
    "            term_dict[term] = ' '\n",
    "\n",
    "for term in tqdm(term_dict): term_dict[term] = stemmed_wrapper(term)\n",
    "    # print(term,\":\" ,term_dict[term]) --> display text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d21238fc-df64-4e4f-9a55-3681230be170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b706ce70a647ea88dcc0af20800758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 7.99 ms, total: 113 ms\n",
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%time df['stemming'] = df['formalisasi'].swifter.apply(stemmingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fac5e94-59bd-4b4a-a75e-2f4ce9a281c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after stemming :\n",
      " ['part', 'time', 'kalau', 'tidak salah', 'khusus', 'mahasiswa'] \n",
      "\n",
      "before stemming :\n",
      " ['part', 'time', 'kalau', 'tidak salah', 'khusus', 'mahasiswa']\n"
     ]
    }
   ],
   "source": [
    "print('after stemming :\\n', df['formalisasi'].iloc[1],'\\n')\n",
    "print('before stemming :\\n', df['stemming'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402d462-d960-402d-9847-9f50a4a6de34",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3da30d9-1cb9-457e-a93e-58acc19f766a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filtering</th>\n",
       "      <th>casefolding</th>\n",
       "      <th>check_exaggeration</th>\n",
       "      <th>repair_exaggeration</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stopword</th>\n",
       "      <th>formalisasi</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pickup #kopi , tetap buka meski tanggal libur ...</td>\n",
       "      <td>Pickup kopi  tetap buka meski tanggal libur Ja...</td>\n",
       "      <td>pickup kopi  tetap buka meski tanggal libur ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>pickup kopi tetap buka meski tangal libur jan ...</td>\n",
       "      <td>[pickup, kopi, tetap, buka, meski, tangal, lib...</td>\n",
       "      <td>[pickup, buka, tangal, libur, ruko, kaliurang,...</td>\n",
       "      <td>[pickup, buka, tangal, libur, rumah toko, kali...</td>\n",
       "      <td>[pickup, buka, tangal, libur, rumah toko, kali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tanyarlfes Part time di kopi kenangan aja ada...</td>\n",
       "      <td>tanyarlfes Part time di kopi kenangan aja ada ...</td>\n",
       "      <td>tanyarlfes part time di kopi kenangan aja ada ...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanyarlfes part time di kopi kenangan aja ada ...</td>\n",
       "      <td>[tanyarlfes, part, time, di, kopi, kenangan, a...</td>\n",
       "      <td>[part, time, kalo, gasalah, khusus, mahasiswa]</td>\n",
       "      <td>[part, time, kalau, tidak salah, khusus, mahas...</td>\n",
       "      <td>[part, time, kalau, tidak salah, khusus, mahas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aku tadi keliling\" naik motor sambil dengerin ...</td>\n",
       "      <td>aku tadi keliling naik motor sambil dengerin r...</td>\n",
       "      <td>aku tadi keliling naik motor sambil dengerin r...</td>\n",
       "      <td>False</td>\n",
       "      <td>aku tadi keliling naik motor sambil dengerin r...</td>\n",
       "      <td>[aku, tadi, keliling, naik, motor, sambil, den...</td>\n",
       "      <td>[keliling, motor, dengerin, radiohead, pesen, ...</td>\n",
       "      <td>[keliling, motor, dengerin, radiohead, pesan, ...</td>\n",
       "      <td>[keliling, motor, dengerin, radiohead, pesan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wah, kopi kenangan nya sudah selesai. Makasih ...</td>\n",
       "      <td>wah kopi kenangan nya sudah selesai Makasih ko...</td>\n",
       "      <td>wah kopi kenangan nya sudah selesai makasih ko...</td>\n",
       "      <td>False</td>\n",
       "      <td>wah kopi kenangan nya sudah selesai makasih ko...</td>\n",
       "      <td>[wah, kopi, kenangan, nya, sudah, selesai, mak...</td>\n",
       "      <td>[selesai, makasih, pahit, manis, harihari, ked...</td>\n",
       "      <td>[selesai, terima kasih, pahit, manis, harihari...</td>\n",
       "      <td>[selesai, terima kasih, pahit, manis, harihari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Menutup tahun dengan kenangan.\\nKopi kenangan ...</td>\n",
       "      <td>Menutup tahun dengan kenanganKopi kenangan dan...</td>\n",
       "      <td>menutup tahun dengan kenangankopi kenangan dan...</td>\n",
       "      <td>False</td>\n",
       "      <td>menutup tahun dengan kenangankopi kenangan dan...</td>\n",
       "      <td>[menutup, tahun, dengan, kenangankopi, kenanga...</td>\n",
       "      <td>[menutup, kenangankopi, konser, lys, htpscostp...</td>\n",
       "      <td>[menutup, kenangankopi, konser, lys, htpscostp...</td>\n",
       "      <td>[tutup, kenangankopi, konser, lys, htpscostpso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Pickup #kopi , tetap buka meski tanggal libur ...   \n",
       "1  @tanyarlfes Part time di kopi kenangan aja ada...   \n",
       "2  aku tadi keliling\" naik motor sambil dengerin ...   \n",
       "3  wah, kopi kenangan nya sudah selesai. Makasih ...   \n",
       "4  Menutup tahun dengan kenangan.\\nKopi kenangan ...   \n",
       "\n",
       "                                           filtering  \\\n",
       "0  Pickup kopi  tetap buka meski tanggal libur Ja...   \n",
       "1  tanyarlfes Part time di kopi kenangan aja ada ...   \n",
       "2  aku tadi keliling naik motor sambil dengerin r...   \n",
       "3  wah kopi kenangan nya sudah selesai Makasih ko...   \n",
       "4  Menutup tahun dengan kenanganKopi kenangan dan...   \n",
       "\n",
       "                                         casefolding  check_exaggeration  \\\n",
       "0  pickup kopi  tetap buka meski tanggal libur ja...               False   \n",
       "1  tanyarlfes part time di kopi kenangan aja ada ...               False   \n",
       "2  aku tadi keliling naik motor sambil dengerin r...               False   \n",
       "3  wah kopi kenangan nya sudah selesai makasih ko...               False   \n",
       "4  menutup tahun dengan kenangankopi kenangan dan...               False   \n",
       "\n",
       "                                 repair_exaggeration  \\\n",
       "0  pickup kopi tetap buka meski tangal libur jan ...   \n",
       "1  tanyarlfes part time di kopi kenangan aja ada ...   \n",
       "2  aku tadi keliling naik motor sambil dengerin r...   \n",
       "3  wah kopi kenangan nya sudah selesai makasih ko...   \n",
       "4  menutup tahun dengan kenangankopi kenangan dan...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [pickup, kopi, tetap, buka, meski, tangal, lib...   \n",
       "1  [tanyarlfes, part, time, di, kopi, kenangan, a...   \n",
       "2  [aku, tadi, keliling, naik, motor, sambil, den...   \n",
       "3  [wah, kopi, kenangan, nya, sudah, selesai, mak...   \n",
       "4  [menutup, tahun, dengan, kenangankopi, kenanga...   \n",
       "\n",
       "                                            stopword  \\\n",
       "0  [pickup, buka, tangal, libur, ruko, kaliurang,...   \n",
       "1     [part, time, kalo, gasalah, khusus, mahasiswa]   \n",
       "2  [keliling, motor, dengerin, radiohead, pesen, ...   \n",
       "3  [selesai, makasih, pahit, manis, harihari, ked...   \n",
       "4  [menutup, kenangankopi, konser, lys, htpscostp...   \n",
       "\n",
       "                                         formalisasi  \\\n",
       "0  [pickup, buka, tangal, libur, rumah toko, kali...   \n",
       "1  [part, time, kalau, tidak salah, khusus, mahas...   \n",
       "2  [keliling, motor, dengerin, radiohead, pesan, ...   \n",
       "3  [selesai, terima kasih, pahit, manis, harihari...   \n",
       "4  [menutup, kenangankopi, konser, lys, htpscostp...   \n",
       "\n",
       "                                            stemming  \n",
       "0  [pickup, buka, tangal, libur, rumah toko, kali...  \n",
       "1  [part, time, kalau, tidak salah, khusus, mahas...  \n",
       "2  [keliling, motor, dengerin, radiohead, pesan, ...  \n",
       "3  [selesai, terima kasih, pahit, manis, harihari...  \n",
       "4  [tutup, kenangankopi, konser, lys, htpscostpso...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7a7d624-c295-483b-a69e-af33bd2976ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(path + \"data/resto-preprocess-2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da401f-e93a-4ea8-9eea-c5ebb5d17fcf",
   "metadata": {},
   "source": [
    "# Data Labelling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef640f4-14ab-4c79-8e32-79ad7c7c4cee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b> Do not change this script\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65247ff3-911f-49a7-a52d-1c1bfcfca2f5",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77217467-2261-4b69-ab14-e70a3e225e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads lexicon positive and negative data\n",
    "lexicon_positive = dict()\n",
    "import csv\n",
    "with open(path + 'dict/lexicon_positive.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        lexicon_positive[row[0]] = int(row[1])\n",
    "\n",
    "lexicon_negative = dict()\n",
    "import csv\n",
    "with open(path + 'dict/lexicon_negative.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        lexicon_negative[row[0]] = int(row[1])\n",
    "        \n",
    "# Function to determine sentiment polarity of tweets        \n",
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "    #for word in text:\n",
    "    score = 0\n",
    "    for word in text:\n",
    "        if (word in lexicon_positive):\n",
    "            score = score + lexicon_positive[word]\n",
    "    for word in text:\n",
    "        if (word in lexicon_negative):\n",
    "            score = score + lexicon_negative[word]\n",
    "    polarity=''\n",
    "    if (score > 0):\n",
    "        polarity = 'positive'\n",
    "    elif (score < 0):\n",
    "        polarity = 'negative'\n",
    "    else:\n",
    "        polarity = 'neutral'\n",
    "    return score, polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6c63a-d690-4ce5-ab17-e21c6e6c4e59",
   "metadata": {},
   "source": [
    "## Start Labelling using Lexicon\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54a51bb0-98fd-45cc-837b-4dbc5639c944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c987f833b2c94b23b35bfe038a9ece77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86 ms, sys: 7.99 ms, total: 94 ms\n",
      "Wall time: 91.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time results = df['stemming'].swifter.apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec49d461-2d31-4704-956e-4ace90f219b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    4916\n",
      "neutral     2357\n",
      "positive    2229\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['polarity_score'] = results[0]\n",
    "df['polarity'] = results[1]\n",
    "print(df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcfbf31-54b6-4ed9-a025-12dd5d5afd57",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da8d6e2-5d2e-42de-91af-df7781694c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path + \"data/resto-labelling-2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "503928fc-a4ea-4e10-adf8-f78353c4b264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filtering</th>\n",
       "      <th>casefolding</th>\n",
       "      <th>check_exaggeration</th>\n",
       "      <th>repair_exaggeration</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>stopword</th>\n",
       "      <th>formalisasi</th>\n",
       "      <th>stemming</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pickup #kopi , tetap buka meski tanggal libur ...</td>\n",
       "      <td>Pickup kopi  tetap buka meski tanggal libur Ja...</td>\n",
       "      <td>pickup kopi  tetap buka meski tanggal libur ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>pickup kopi tetap buka meski tangal libur jan ...</td>\n",
       "      <td>[pickup, kopi, tetap, buka, meski, tangal, lib...</td>\n",
       "      <td>[pickup, buka, tangal, libur, ruko, kaliurang,...</td>\n",
       "      <td>[pickup, buka, tangal, libur, rumah toko, kali...</td>\n",
       "      <td>[pickup, buka, tangal, libur, rumah toko, kali...</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tanyarlfes Part time di kopi kenangan aja ada...</td>\n",
       "      <td>tanyarlfes Part time di kopi kenangan aja ada ...</td>\n",
       "      <td>tanyarlfes part time di kopi kenangan aja ada ...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanyarlfes part time di kopi kenangan aja ada ...</td>\n",
       "      <td>[tanyarlfes, part, time, di, kopi, kenangan, a...</td>\n",
       "      <td>[part, time, kalo, gasalah, khusus, mahasiswa]</td>\n",
       "      <td>[part, time, kalau, tidak salah, khusus, mahas...</td>\n",
       "      <td>[part, time, kalau, tidak salah, khusus, mahas...</td>\n",
       "      <td>-1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aku tadi keliling\" naik motor sambil dengerin ...</td>\n",
       "      <td>aku tadi keliling naik motor sambil dengerin r...</td>\n",
       "      <td>aku tadi keliling naik motor sambil dengerin r...</td>\n",
       "      <td>False</td>\n",
       "      <td>aku tadi keliling naik motor sambil dengerin r...</td>\n",
       "      <td>[aku, tadi, keliling, naik, motor, sambil, den...</td>\n",
       "      <td>[keliling, motor, dengerin, radiohead, pesen, ...</td>\n",
       "      <td>[keliling, motor, dengerin, radiohead, pesan, ...</td>\n",
       "      <td>[keliling, motor, dengerin, radiohead, pesan, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wah, kopi kenangan nya sudah selesai. Makasih ...</td>\n",
       "      <td>wah kopi kenangan nya sudah selesai Makasih ko...</td>\n",
       "      <td>wah kopi kenangan nya sudah selesai makasih ko...</td>\n",
       "      <td>False</td>\n",
       "      <td>wah kopi kenangan nya sudah selesai makasih ko...</td>\n",
       "      <td>[wah, kopi, kenangan, nya, sudah, selesai, mak...</td>\n",
       "      <td>[selesai, makasih, pahit, manis, harihari, ked...</td>\n",
       "      <td>[selesai, terima kasih, pahit, manis, harihari...</td>\n",
       "      <td>[selesai, terima kasih, pahit, manis, harihari...</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Menutup tahun dengan kenangan.\\nKopi kenangan ...</td>\n",
       "      <td>Menutup tahun dengan kenanganKopi kenangan dan...</td>\n",
       "      <td>menutup tahun dengan kenangankopi kenangan dan...</td>\n",
       "      <td>False</td>\n",
       "      <td>menutup tahun dengan kenangankopi kenangan dan...</td>\n",
       "      <td>[menutup, tahun, dengan, kenangankopi, kenanga...</td>\n",
       "      <td>[menutup, kenangankopi, konser, lys, htpscostp...</td>\n",
       "      <td>[menutup, kenangankopi, konser, lys, htpscostp...</td>\n",
       "      <td>[tutup, kenangankopi, konser, lys, htpscostpso...</td>\n",
       "      <td>-2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Pickup #kopi , tetap buka meski tanggal libur ...   \n",
       "1  @tanyarlfes Part time di kopi kenangan aja ada...   \n",
       "2  aku tadi keliling\" naik motor sambil dengerin ...   \n",
       "3  wah, kopi kenangan nya sudah selesai. Makasih ...   \n",
       "4  Menutup tahun dengan kenangan.\\nKopi kenangan ...   \n",
       "\n",
       "                                           filtering  \\\n",
       "0  Pickup kopi  tetap buka meski tanggal libur Ja...   \n",
       "1  tanyarlfes Part time di kopi kenangan aja ada ...   \n",
       "2  aku tadi keliling naik motor sambil dengerin r...   \n",
       "3  wah kopi kenangan nya sudah selesai Makasih ko...   \n",
       "4  Menutup tahun dengan kenanganKopi kenangan dan...   \n",
       "\n",
       "                                         casefolding  check_exaggeration  \\\n",
       "0  pickup kopi  tetap buka meski tanggal libur ja...               False   \n",
       "1  tanyarlfes part time di kopi kenangan aja ada ...               False   \n",
       "2  aku tadi keliling naik motor sambil dengerin r...               False   \n",
       "3  wah kopi kenangan nya sudah selesai makasih ko...               False   \n",
       "4  menutup tahun dengan kenangankopi kenangan dan...               False   \n",
       "\n",
       "                                 repair_exaggeration  \\\n",
       "0  pickup kopi tetap buka meski tangal libur jan ...   \n",
       "1  tanyarlfes part time di kopi kenangan aja ada ...   \n",
       "2  aku tadi keliling naik motor sambil dengerin r...   \n",
       "3  wah kopi kenangan nya sudah selesai makasih ko...   \n",
       "4  menutup tahun dengan kenangankopi kenangan dan...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [pickup, kopi, tetap, buka, meski, tangal, lib...   \n",
       "1  [tanyarlfes, part, time, di, kopi, kenangan, a...   \n",
       "2  [aku, tadi, keliling, naik, motor, sambil, den...   \n",
       "3  [wah, kopi, kenangan, nya, sudah, selesai, mak...   \n",
       "4  [menutup, tahun, dengan, kenangankopi, kenanga...   \n",
       "\n",
       "                                            stopword  \\\n",
       "0  [pickup, buka, tangal, libur, ruko, kaliurang,...   \n",
       "1     [part, time, kalo, gasalah, khusus, mahasiswa]   \n",
       "2  [keliling, motor, dengerin, radiohead, pesen, ...   \n",
       "3  [selesai, makasih, pahit, manis, harihari, ked...   \n",
       "4  [menutup, kenangankopi, konser, lys, htpscostp...   \n",
       "\n",
       "                                         formalisasi  \\\n",
       "0  [pickup, buka, tangal, libur, rumah toko, kali...   \n",
       "1  [part, time, kalau, tidak salah, khusus, mahas...   \n",
       "2  [keliling, motor, dengerin, radiohead, pesan, ...   \n",
       "3  [selesai, terima kasih, pahit, manis, harihari...   \n",
       "4  [menutup, kenangankopi, konser, lys, htpscostp...   \n",
       "\n",
       "                                            stemming  polarity_score  polarity  \n",
       "0  [pickup, buka, tangal, libur, rumah toko, kali...               3  positive  \n",
       "1  [part, time, kalau, tidak salah, khusus, mahas...              -1  negative  \n",
       "2  [keliling, motor, dengerin, radiohead, pesan, ...               5  positive  \n",
       "3  [selesai, terima kasih, pahit, manis, harihari...              10  positive  \n",
       "4  [tutup, kenangankopi, konser, lys, htpscostpso...              -2  negative  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27567230-b221-43c7-8e49-3be070e32e55",
   "metadata": {},
   "source": [
    "## Comparasion Sentiment Polarity on Tweets Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b202884d-e8ae-4e3d-abd3-67f84266d64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selamat menjelang subuh pelangi-ku untuk awal minggu ini, nikmatilah Seteguk Kopi kentalmu demi meresapi semua kenangan yang sudah berlalu. Seperti mentari yang tiap pagi terbit. Tanpa peduli suka atau tidak suka. https://t.co/LXE4FnvDCX</td>\n",
       "      <td>24</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5. Melakukan Inovasi Produk\\n\\nKopi Kenangan berinovasi menjual produk kopi siap minum dalam bentuk botol yang dijual di supermarket. Jadi, bestie bisa lebih mudah ditemukan oleh para penikmat kopi. \\n\\nMalah sekarang juga iklannya juga udah berseliweran ya di tv~ https://t.co/caLUZC7d8u</td>\n",
       "      <td>23</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bos ni emang kadang kadang kadang kadang ni. dari pagi buta cuaca hujan dingin pol eh tiba2 dateng kopi kenangan. dikasih asupan es ☺🤝🏻 makasih banyak pak bos</td>\n",
       "      <td>21</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Bang_Garr Fii amanillah Bang. Selamat menikmati bandara baru Jogja, selamat menikmati suasana Jogja yang terbuat dari rindu dan kenangan 😊✌ besok cobain kopi joss Bang, kopi kasih arang panas membara 😁</td>\n",
       "      <td>21</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bismillah\\nThrowback desain 2017\\n\\nFull porto: https://t.co/f6hBesW31h\\n\\nYang butuh jasa desain, jasa bikin logo olshop, ilustrasi, jasa desain feed ig, dll bisa dm yaa :)\\n\\nNasi Goreng Solaria #BongkarPembantaiKM50 #BinJin UU ITE Sambo RANS PIK Kopi Kenangan https://t.co/sNuI7S3CGy</td>\n",
       "      <td>20</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thank you @belajarlagiHQ for a memorable (7+) 5-week bootcamp! The best team there is. \\nSpecial thanks untuk faciku @budak_milktea yang selalu menyemangati. Dan teman2 tim 9 para penyuka kopi kenangan. https://t.co/13yPwyw4J1</td>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@hanyauntukmu_kk Moment paling cocok itu pas weekend dong, kumpul bareng bestie sambil ngobrol2 santai, nostalgia kenangan masa lalu hahaha tentunya dgn ditemani kopi kenangan yg pastinya bikin suasananya makin seru #KenanganHanyaUntukmu\\n\\nNgopi bareng yuk bestie🥰 @ajekrina @tweetyone_ @sugaaBST</td>\n",
       "      <td>18</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kita patut bangga &amp;amp; mendukung Kopi Kenangan sebagai brand kopi lokal yg sukses. Growth nya yg pesat ini membuat mereka berambisi menyaingi brand kopi dunia.\\n\\nMenurut kamu strategi apa yg menarik dari Kopi Kenangan ini? Reply dibawah yuk!</td>\n",
       "      <td>17</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trik membuat sepatu menjadi kinclong hanya sekejap. Foam pembersih sepatu, Viral nih🤭\\n\\nBeli👉 https://t.co/ovUrbMI7mY\\n\\nSusilo Bambang Yudhoyono Habib Bahar 17 Agustus Sambo Kopi Kenangan Bakmi GM Enzy Cakep Lomba Paket D Presiden Joko Widodo UU ITE #BongkarPembantaiKM50 https://t.co/NFNWbge8WS</td>\n",
       "      <td>17</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Besok 12.12, beberapa gerai makanan dan minuman menyediakan diskon untuk promo 12.12. Kopi Kenangan menyediakan promo beli 2 kopi hanya Rp 29.000.\\n#besok1212 #harbolnas #harbolnas1212 #promo1212 #diskon #promo #starbuck #kopikenangan #chigo\\nhttps://t.co/OajX0D5dAt</td>\n",
       "      <td>16</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                         text  \\\n",
       "1                                                               Selamat menjelang subuh pelangi-ku untuk awal minggu ini, nikmatilah Seteguk Kopi kentalmu demi meresapi semua kenangan yang sudah berlalu. Seperti mentari yang tiap pagi terbit. Tanpa peduli suka atau tidak suka. https://t.co/LXE4FnvDCX   \n",
       "2            5. Melakukan Inovasi Produk\\n\\nKopi Kenangan berinovasi menjual produk kopi siap minum dalam bentuk botol yang dijual di supermarket. Jadi, bestie bisa lebih mudah ditemukan oleh para penikmat kopi. \\n\\nMalah sekarang juga iklannya juga udah berseliweran ya di tv~ https://t.co/caLUZC7d8u   \n",
       "3                                                                                                                                              bos ni emang kadang kadang kadang kadang ni. dari pagi buta cuaca hujan dingin pol eh tiba2 dateng kopi kenangan. dikasih asupan es ☺🤝🏻 makasih banyak pak bos   \n",
       "4                                                                                                  @Bang_Garr Fii amanillah Bang. Selamat menikmati bandara baru Jogja, selamat menikmati suasana Jogja yang terbuat dari rindu dan kenangan 😊✌ besok cobain kopi joss Bang, kopi kasih arang panas membara 😁   \n",
       "5              Bismillah\\nThrowback desain 2017\\n\\nFull porto: https://t.co/f6hBesW31h\\n\\nYang butuh jasa desain, jasa bikin logo olshop, ilustrasi, jasa desain feed ig, dll bisa dm yaa :)\\n\\nNasi Goreng Solaria #BongkarPembantaiKM50 #BinJin UU ITE Sambo RANS PIK Kopi Kenangan https://t.co/sNuI7S3CGy   \n",
       "6                                                                          Thank you @belajarlagiHQ for a memorable (7+) 5-week bootcamp! The best team there is. \\nSpecial thanks untuk faciku @budak_milktea yang selalu menyemangati. Dan teman2 tim 9 para penyuka kopi kenangan. https://t.co/13yPwyw4J1   \n",
       "7   @hanyauntukmu_kk Moment paling cocok itu pas weekend dong, kumpul bareng bestie sambil ngobrol2 santai, nostalgia kenangan masa lalu hahaha tentunya dgn ditemani kopi kenangan yg pastinya bikin suasananya makin seru #KenanganHanyaUntukmu\\n\\nNgopi bareng yuk bestie🥰 @ajekrina @tweetyone_ @sugaaBST   \n",
       "8                                                         Kita patut bangga &amp; mendukung Kopi Kenangan sebagai brand kopi lokal yg sukses. Growth nya yg pesat ini membuat mereka berambisi menyaingi brand kopi dunia.\\n\\nMenurut kamu strategi apa yg menarik dari Kopi Kenangan ini? Reply dibawah yuk!   \n",
       "9   Trik membuat sepatu menjadi kinclong hanya sekejap. Foam pembersih sepatu, Viral nih🤭\\n\\nBeli👉 https://t.co/ovUrbMI7mY\\n\\nSusilo Bambang Yudhoyono Habib Bahar 17 Agustus Sambo Kopi Kenangan Bakmi GM Enzy Cakep Lomba Paket D Presiden Joko Widodo UU ITE #BongkarPembantaiKM50 https://t.co/NFNWbge8WS   \n",
       "10                                 Besok 12.12, beberapa gerai makanan dan minuman menyediakan diskon untuk promo 12.12. Kopi Kenangan menyediakan promo beli 2 kopi hanya Rp 29.000.\\n#besok1212 #harbolnas #harbolnas1212 #promo1212 #diskon #promo #starbuck #kopikenangan #chigo\\nhttps://t.co/OajX0D5dAt   \n",
       "\n",
       "    polarity_score  polarity  \n",
       "1               24  positive  \n",
       "2               23  positive  \n",
       "3               21  positive  \n",
       "4               21  positive  \n",
       "5               20  positive  \n",
       "6               19  positive  \n",
       "7               18  positive  \n",
       "8               17  positive  \n",
       "9               17  positive  \n",
       "10              16  positive  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 3000)\n",
    "positive_tweets = df[df['polarity'] == 'positive']\n",
    "positive_tweets = positive_tweets[['text', 'polarity_score', 'polarity']].sort_values(by = 'polarity_score', ascending=False).reset_index(drop = True)\n",
    "positive_tweets.index += 1\n",
    "positive_tweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eab21e1-75be-4e22-adb9-fc98a036487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anjgg ASAM LAMBUNG INI KEKNYA GUA, ANJGG KOK TUMBEN PARAH BGT\\n\\nSAMPE GUE MENGGIGIL + MUAL BGT, DADA GUE BENERAN KEK GMN YA, YAA YG PUNYA ASAM LAMBUNG PASTI PAHAMM\\n\\nmasa gegara kopi kenangan doang anjird, tumbenan bgt ini guaa😭😭😭 mana besok kuliah offlen huweeeee sedih bgtt</td>\n",
       "      <td>-51</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@orgilthingy binar nakal, NAKAL BANGET. dia kalau disuruh buat berhenti minum kopi atau tidur cepet susahnya Allahuakbar. nyebut pokoke, ada aja yang dijawab. no kopi no life. mumet, mual, meriang bukan sanmol yang dicari, tapi kopi kenangan huft. anaknya bertanggungjawab, suka NGOMEL ANJIR.</td>\n",
       "      <td>-47</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sebenarnya hari ini gw ga mau keluar. gw boongin anak ini gw ada di kopi kenangan neo soho padahal kemaren. eh anjir pas dia di sbux neo gw di samperin tapi gw ga ada wkwk\\n\\nmau ga mau gw yg nyamperin dia ke sbux neo\\n\\nini anak WA dia sering gw block dan gw ga pernah save nomor dia https://t.co/q6fhqyRgsb</td>\n",
       "      <td>-45</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@PolJokesID mungkin sebaiknya malah menuntut perusahaan pemerintah yang ga sesuai namanya.\\nPDAM itu perusahaan daerah air minum tapi boro2 airnya bisa diminum kalo ga mati, buteknya kaya warnanya kopi kenangan 😅\\nnegara lain air keran bisa langsung diminum loh 🙏🏻</td>\n",
       "      <td>-43</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>demi Allah gue gugup bgt masuk bioskop gara gara bawa kopi kenangan trs saking gugupnya malah jd ngaku sendiri anjggg “mas kalo bawa minuman dr luar nitip dmn ya?”</td>\n",
       "      <td>-40</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pengen cobain kopi... selama ini gw gapernah cobain janjiw, fore, kenangan, dll. gak tau knp ya akhir2 ini pgn minum kopi gara2 nonton hospital playlist, karna pada mesen kopi mulu di dramanya hhh. trus jd penasaran, apa semua kopi bikin gak ngantuk? 🤔</td>\n",
       "      <td>-40</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada deng kesedihan dikitt, ditolak kopi kenangan, tpi ga sedih sedih bgt karna bodo amat bleee</td>\n",
       "      <td>-38</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@amourdem4vie YA KANNN ANJR!!! gue terakhir minum kopi kenangan malah jantung gue detak kenceng bgt ampe gua panik klo itu hari terakhir gue napas. abis itu gue kapok gamau beli kopi kopian</td>\n",
       "      <td>-38</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@convomfs tapi sejak ada kopi kenangan aku udh ga merenung lagi di tempat kopi karen selalu ambil mantanchino🤣\\nmerenung dikit di tempat teh nyari yang promo kalo ga ada ambilnya ichitan thaitea atau numilktea\\ndi yogurt ambil cimory squeeze taro atau ketan item, susu cimory regal</td>\n",
       "      <td>-37</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Demi allah gak lagi lagi gue minum kopi kenangan jam 10 malem. Gini hari belum tidur juga ya allahhh padahal badan rasanya remuk banget 3 minggu berturut2 masuk sore tapi mata gamau meremmm😭😭😭😭😭😭😭</td>\n",
       "      <td>-37</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                    text  \\\n",
       "1                                  Anjgg ASAM LAMBUNG INI KEKNYA GUA, ANJGG KOK TUMBEN PARAH BGT\\n\\nSAMPE GUE MENGGIGIL + MUAL BGT, DADA GUE BENERAN KEK GMN YA, YAA YG PUNYA ASAM LAMBUNG PASTI PAHAMM\\n\\nmasa gegara kopi kenangan doang anjird, tumbenan bgt ini guaa😭😭😭 mana besok kuliah offlen huweeeee sedih bgtt   \n",
       "2                   @orgilthingy binar nakal, NAKAL BANGET. dia kalau disuruh buat berhenti minum kopi atau tidur cepet susahnya Allahuakbar. nyebut pokoke, ada aja yang dijawab. no kopi no life. mumet, mual, meriang bukan sanmol yang dicari, tapi kopi kenangan huft. anaknya bertanggungjawab, suka NGOMEL ANJIR.   \n",
       "3   sebenarnya hari ini gw ga mau keluar. gw boongin anak ini gw ada di kopi kenangan neo soho padahal kemaren. eh anjir pas dia di sbux neo gw di samperin tapi gw ga ada wkwk\\n\\nmau ga mau gw yg nyamperin dia ke sbux neo\\n\\nini anak WA dia sering gw block dan gw ga pernah save nomor dia https://t.co/q6fhqyRgsb   \n",
       "4                                               @PolJokesID mungkin sebaiknya malah menuntut perusahaan pemerintah yang ga sesuai namanya.\\nPDAM itu perusahaan daerah air minum tapi boro2 airnya bisa diminum kalo ga mati, buteknya kaya warnanya kopi kenangan 😅\\nnegara lain air keran bisa langsung diminum loh 🙏🏻   \n",
       "5                                                                                                                                                    demi Allah gue gugup bgt masuk bioskop gara gara bawa kopi kenangan trs saking gugupnya malah jd ngaku sendiri anjggg “mas kalo bawa minuman dr luar nitip dmn ya?”   \n",
       "6                                                           pengen cobain kopi... selama ini gw gapernah cobain janjiw, fore, kenangan, dll. gak tau knp ya akhir2 ini pgn minum kopi gara2 nonton hospital playlist, karna pada mesen kopi mulu di dramanya hhh. trus jd penasaran, apa semua kopi bikin gak ngantuk? 🤔   \n",
       "7                                                                                                                                                                                                                         ada deng kesedihan dikitt, ditolak kopi kenangan, tpi ga sedih sedih bgt karna bodo amat bleee   \n",
       "8                                                                                                                          @amourdem4vie YA KANNN ANJR!!! gue terakhir minum kopi kenangan malah jantung gue detak kenceng bgt ampe gua panik klo itu hari terakhir gue napas. abis itu gue kapok gamau beli kopi kopian   \n",
       "9                              @convomfs tapi sejak ada kopi kenangan aku udh ga merenung lagi di tempat kopi karen selalu ambil mantanchino🤣\\nmerenung dikit di tempat teh nyari yang promo kalo ga ada ambilnya ichitan thaitea atau numilktea\\ndi yogurt ambil cimory squeeze taro atau ketan item, susu cimory regal   \n",
       "10                                                                                                                  Demi allah gak lagi lagi gue minum kopi kenangan jam 10 malem. Gini hari belum tidur juga ya allahhh padahal badan rasanya remuk banget 3 minggu berturut2 masuk sore tapi mata gamau meremmm😭😭😭😭😭😭😭   \n",
       "\n",
       "    polarity_score  polarity  \n",
       "1              -51  negative  \n",
       "2              -47  negative  \n",
       "3              -45  negative  \n",
       "4              -43  negative  \n",
       "5              -40  negative  \n",
       "6              -40  negative  \n",
       "7              -38  negative  \n",
       "8              -38  negative  \n",
       "9              -37  negative  \n",
       "10             -37  negative  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 3000)\n",
    "negative_tweets = df[df['polarity'] == 'negative']\n",
    "negative_tweets = negative_tweets[['text', 'polarity_score', 'polarity']].sort_values(by = 'polarity_score', ascending=True)[0:10].reset_index(drop = True)\n",
    "negative_tweets.index += 1\n",
    "negative_tweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5805078-93a4-40e4-9bbc-1461950e6ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>btw logonya mbc gayo ngingetin sama kopi kenangan dah wkwk</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@lewd_pics_jpg Kopi kenangan ya</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kata temenku mending kopi kenangan yg botol https://t.co/0b69yHkkwr</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@andalasfess kopi kenangan</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@clearindigo Some time... mau kopi kenangan</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@rubah_galak kopi kenangan</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Info ngopi di Banyuwangi yang enak di mana genkss?\\n\\nAla ala kopi kenangan tapi yang ori Banyuwangi 😉🙏</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@sbyfess Aku kopi kenangan spbu ngagel 😭</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kopi kenangan tetep no 1 https://t.co/35GWk7edx4</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@FFOODFESS yang kopi kenangan itu?</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "1                                                btw logonya mbc gayo ngingetin sama kopi kenangan dah wkwk   \n",
       "2                                                                           @lewd_pics_jpg Kopi kenangan ya   \n",
       "3                                       kata temenku mending kopi kenangan yg botol https://t.co/0b69yHkkwr   \n",
       "4                                                                                @andalasfess kopi kenangan   \n",
       "5                                                               @clearindigo Some time... mau kopi kenangan   \n",
       "6                                                                                @rubah_galak kopi kenangan   \n",
       "7   Info ngopi di Banyuwangi yang enak di mana genkss?\\n\\nAla ala kopi kenangan tapi yang ori Banyuwangi 😉🙏   \n",
       "8                                                                  @sbyfess Aku kopi kenangan spbu ngagel 😭   \n",
       "9                                                          Kopi kenangan tetep no 1 https://t.co/35GWk7edx4   \n",
       "10                                                                       @FFOODFESS yang kopi kenangan itu?   \n",
       "\n",
       "    polarity_score polarity  \n",
       "1                0  neutral  \n",
       "2                0  neutral  \n",
       "3                0  neutral  \n",
       "4                0  neutral  \n",
       "5                0  neutral  \n",
       "6                0  neutral  \n",
       "7                0  neutral  \n",
       "8                0  neutral  \n",
       "9                0  neutral  \n",
       "10               0  neutral  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 3000)\n",
    "neutral_tweets = df[df['polarity'] == 'neutral']\n",
    "neutral_tweets = neutral_tweets[['text', 'polarity_score', 'polarity']].sort_values(by = 'polarity_score', ascending=True)[0:10].reset_index(drop = True)\n",
    "neutral_tweets.index += 1\n",
    "neutral_tweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2f8b5-0b22-4c7a-b73c-e8e609adb1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "local-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
